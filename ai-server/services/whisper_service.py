"""
Whisper STT Service + Demucs ë³´ì»¬ ë¶„ë¦¬ (CLI) + ë³´ì»¬ ì—ë„ˆì§€ ì²´í¬ + í™˜ê° ê°ì§€
- Demucs CLIë¡œ ë°°ê²½ìŒì•… ì œê±° (python -m demucs.separate)
- ë³´ì»¬ ì—ë„ˆì§€(RMS) ì²´í¬ë¡œ BGM only ì˜ìƒ ê°ì§€
- OpenAI Whisper APIë¡œ ì •í™•í•œ ì „ì‚¬
- Windows í•œê¸€ ê²½ë¡œ í˜¸í™˜
"""

import os
import re
import sys
import wave
import struct
import math
import tempfile
import subprocess
import shutil
import requests
import json
from openai import OpenAI


class WhisperService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.use_demucs = self._check_demucs()
        
        # ë³´ì»¬ ì—ë„ˆì§€ ì„ê³„ê°’ (ì´ ê°’ ì´í•˜ë©´ "ìŒì„± ì—†ìŒ"ìœ¼ë¡œ íŒì •)
        self.vocal_energy_threshold = 0.01  # RMS ê°’
        
        # í™˜ê° ê°ì§€ìš© íŒ¨í„´
        self.hallucination_patterns = [
            'ultramarine', 'Studio', 'Frappe', 'goes to',
            'Subscribe', 'Thank you for watching',
            'MR', 'Instrumental', 'legend', 'called', 'eless',
        ]
        
        # ì´ëª¨ì§€ íŒ¨í„´
        self.emoji_pattern = re.compile(
            "["
            "\U0001F300-\U0001F9FF"
            "\U00002600-\U000027BF"
            "\U0001F600-\U0001F64F"
            "\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF"
            "]+"
        )
    
    def _check_demucs(self) -> bool:
        """Demucs CLI ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ (python -m ë°©ì‹)"""
        try:
            result = subprocess.run(
                [sys.executable, '-m', 'demucs.separate', '--help'],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode == 0:
                print("    âœ… Demucs ì‚¬ìš© ê°€ëŠ¥ - ë³´ì»¬ ë¶„ë¦¬ í™œì„±í™”")
                return True
            return False
        except Exception as e:
            print(f"    âš ï¸ Demucs ë¯¸ì„¤ì¹˜ - ë³´ì»¬ ë¶„ë¦¬ ë¹„í™œì„±í™”: {e}")
            return False
    
    def transcribe_file(self, file) -> dict:
        """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì „ì‚¬"""
        with tempfile.NamedTemporaryFile(delete=False, suffix=self._get_suffix(file.filename)) as tmp:
            file.save(tmp.name)
            tmp_path = tmp.name
        
        try:
            return self._process_and_transcribe(tmp_path)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
    
    def transcribe_url(self, url: str) -> dict:
        """URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í›„ ì „ì‚¬"""
        response = requests.get(url, stream=True, timeout=300)
        response.raise_for_status()
        
        suffix = self._get_suffix_from_url(url)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            for chunk in response.iter_content(chunk_size=8192):
                tmp.write(chunk)
            tmp_path = tmp.name
        
        try:
            return self._process_and_transcribe(tmp_path)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
    
    def _process_and_transcribe(self, file_path: str) -> dict:
        """
        ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
        1. íŒŒì¼ í¬ê¸° í™•ì¸
        2. ì˜ìƒ duration ì¶”ì¶œ
        3. í•„ìš”ì‹œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        4. Demucsë¡œ ë³´ì»¬ ë¶„ë¦¬
        5. ë³´ì»¬ ì—ë„ˆì§€ ì²´í¬ (BGM only ê°ì§€)
        6. Whisperë¡œ ì „ì‚¬
        7. í™˜ê° ê°ì§€ ë° ì²˜ë¦¬
        """
        file_size = os.path.getsize(file_path)
        print(f"    ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size / (1024*1024):.1f}MB")
        
        # ì˜ìƒ duration ì¶”ì¶œ
        duration = self._get_duration(file_path)
        print(f"    â±ï¸ ì˜ìƒ ê¸¸ì´: {duration:.1f}ì´ˆ" if duration else "    â±ï¸ ì˜ìƒ ê¸¸ì´: ì•Œ ìˆ˜ ì—†ìŒ")
        
        audio_path = None
        vocals_path = None
        demucs_output_dir = None
        
        try:
            # Step 1: ì˜¤ë””ì˜¤ ì¶”ì¶œ
            print(f"    ğŸ”Š ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
            audio_path = self._extract_audio(file_path)
            if not audio_path:
                raise Exception("ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
            
            # Step 2: Demucs ë³´ì»¬ ë¶„ë¦¬ (CLI)
            if self.use_demucs:
                print(f"    ğŸ¤ ë³´ì»¬ ë¶„ë¦¬ ì¤‘ (Demucs)...")
                vocals_path, demucs_output_dir = self._separate_vocals_cli(audio_path)
                
                if vocals_path:
                    vocals_size = os.path.getsize(vocals_path)
                    print(f"    âœ… ë³´ì»¬ ë¶„ë¦¬ ì™„ë£Œ: {vocals_size / (1024*1024):.1f}MB")
                    
                    # Step 3: ë³´ì»¬ ì—ë„ˆì§€ ì²´í¬
                    vocal_energy = self._check_vocal_energy(vocals_path)
                    print(f"    ğŸ”Š ë³´ì»¬ ì—ë„ˆì§€: {vocal_energy:.4f} (ì„ê³„ê°’: {self.vocal_energy_threshold})")
                    
                    if vocal_energy < self.vocal_energy_threshold:
                        print(f"    ğŸ”‡ ìŒì„± ì—†ìŒ ê°ì§€ - BGM only ì˜ìƒ")
                        return {
                            "segments": [],
                            "full_text": "",
                            "duration": duration,
                            "detected_duration": None,
                            "is_hallucination": False,
                            "no_speech": True,
                            "vocal_energy": vocal_energy
                        }
                    
                    transcribe_path = vocals_path
                else:
                    print(f"    âš ï¸ ë³´ì»¬ ë¶„ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")
                    transcribe_path = audio_path
            else:
                transcribe_path = audio_path
            
            # Step 4: Whisper ì „ì‚¬
            print(f"    ğŸ“ Whisper ì „ì‚¬ ì¤‘...")
            result = self._transcribe(transcribe_path)
            
            # Step 5: í™˜ê° ê°ì§€
            is_hallucination, reason = self._is_likely_hallucination(result, duration)
            if is_hallucination:
                print(f"    ğŸš¨ í™˜ê° ê°ì§€ë¨ - {reason}")
                result = {
                    "segments": [],
                    "full_text": "",
                    "detected_duration": result.get('detected_duration'),
                    "is_hallucination": True,
                    "hallucination_reason": reason
                }
            else:
                result["is_hallucination"] = False
            
            result['duration'] = duration
            result['no_speech'] = False
            
            return result
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if audio_path and os.path.exists(audio_path):
                os.remove(audio_path)
            if demucs_output_dir and os.path.exists(demucs_output_dir):
                shutil.rmtree(demucs_output_dir, ignore_errors=True)
    
    def _separate_vocals_cli(self, audio_path: str) -> tuple:
        """
        Demucs CLIë¡œ ë³´ì»¬ ë¶„ë¦¬ (python -m ë°©ì‹)
        Returns: (vocals_path, output_dir) or (None, None)
        """
        try:
            # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì˜ì–´ ê²½ë¡œ ì‚¬ìš©)
            output_dir = tempfile.mkdtemp(prefix="demucs_")
            
            # Demucs CLI ì‹¤í–‰ (python -m ë°©ì‹)
            cmd = [
                sys.executable, '-m', 'demucs.separate',
                '--two-stems', 'vocals',  # vocalsì™€ no_vocalsë§Œ ë¶„ë¦¬
                '-n', 'htdemucs',          # ëª¨ë¸
                '-o', output_dir,          # ì¶œë ¥ ë””ë ‰í† ë¦¬
                '--mp3',                   # MP3ë¡œ ì¶œë ¥ (ìš©ëŸ‰ ì ˆì•½)
                '--mp3-bitrate', '128',
                audio_path
            ]
            
            print(f"    ğŸ”„ Demucs ì‹¤í–‰ ì¤‘... (1-2ë¶„ ì†Œìš”)")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            if result.returncode != 0:
                print(f"    âŒ Demucs ì—ëŸ¬: {result.stderr[:200]}")
                return None, None
            
            # ì¶œë ¥ íŒŒì¼ ì°¾ê¸°
            # êµ¬ì¡°: output_dir/htdemucs/track_name/vocals.mp3
            audio_name = os.path.splitext(os.path.basename(audio_path))[0]
            vocals_path = os.path.join(output_dir, 'htdemucs', audio_name, 'vocals.mp3')
            
            if os.path.exists(vocals_path):
                return vocals_path, output_dir
            
            # ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„ (wav í™•ì¥ì)
            vocals_wav = os.path.join(output_dir, 'htdemucs', audio_name, 'vocals.wav')
            if os.path.exists(vocals_wav):
                return vocals_wav, output_dir
            
            print(f"    âŒ ë³´ì»¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # ë””ë²„ê¹…: ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
            for root, dirs, files in os.walk(output_dir):
                for f in files:
                    print(f"    ğŸ“„ {os.path.join(root, f)}")
            return None, None
            
        except subprocess.TimeoutExpired:
            print(f"    âŒ Demucs íƒ€ì„ì•„ì›ƒ (5ë¶„ ì´ˆê³¼)")
            return None, None
        except Exception as e:
            print(f"    âŒ Demucs ì—ëŸ¬: {e}")
            return None, None
    
    def _check_vocal_energy(self, audio_path: str) -> float:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì˜ RMS(Root Mean Square) ì—ë„ˆì§€ ê³„ì‚°
        ë‚®ì€ ê°’ = ìŒì„± ì—†ìŒ (BGM only)
        """
        try:
            # ffmpegë¡œ WAV ë³€í™˜ í›„ ë¶„ì„ (MP3 ì§ì ‘ ë¶„ì„ ì–´ë ¤ì›€)
            temp_wav = tempfile.mktemp(suffix='.wav')
            
            cmd = [
                'ffmpeg', '-i', audio_path,
                '-ar', '16000',  # 16kHz
                '-ac', '1',      # ëª¨ë…¸
                '-y',
                temp_wav
            ]
            
            subprocess.run(cmd, capture_output=True, timeout=30)
            
            if not os.path.exists(temp_wav):
                return 1.0  # ë³€í™˜ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ (ìŒì„± ìˆìŒìœ¼ë¡œ ì²˜ë¦¬)
            
            # WAV íŒŒì¼ ì½ê¸°
            try:
                with wave.open(temp_wav, 'rb') as wav:
                    n_frames = wav.getnframes()
                    n_channels = wav.getnchannels()
                    sample_width = wav.getsampwidth()
                    
                    # ìƒ˜í”Œ ì½ê¸°
                    frames = wav.readframes(n_frames)
                    
                    # 16bit PCM ê°€ì •
                    if sample_width == 2:
                        fmt = f'<{n_frames * n_channels}h'
                        samples = struct.unpack(fmt, frames)
                        
                        # RMS ê³„ì‚°
                        sum_squares = sum(s * s for s in samples)
                        rms = math.sqrt(sum_squares / len(samples)) / 32768.0  # ì •ê·œí™”
                        
                        return rms
            finally:
                if os.path.exists(temp_wav):
                    os.remove(temp_wav)
            
            return 1.0  # ê¸°ë³¸ê°’
            
        except Exception as e:
            print(f"    âš ï¸ ì—ë„ˆì§€ ì²´í¬ ì‹¤íŒ¨: {e}")
            return 1.0  # ì‹¤íŒ¨ì‹œ ìŒì„± ìˆìŒìœ¼ë¡œ ì²˜ë¦¬
    
    def _is_likely_hallucination(self, result: dict, duration: float = None) -> tuple:
        """í™˜ê° ê°ì§€"""
        segments = result.get('segments', [])
        full_text = result.get('full_text', '')
        
        if not full_text or len(full_text.strip()) < 5:
            return False, ""
        
        hallucination_score = 0
        reasons = []
        
        # 1. ì´ëª¨ì§€ ê²€ì‚¬
        emojis = self.emoji_pattern.findall(full_text)
        non_emoji_text = self.emoji_pattern.sub('', full_text).strip()
        
        if len(emojis) >= 3:
            if len(non_emoji_text) < 20:
                hallucination_score += 60
                reasons.append(f"ì´ëª¨ì§€ë§Œ ìˆìŒ: {len(emojis)}ê°œ")
            else:
                hallucination_score += 30
                reasons.append(f"ì´ëª¨ì§€ ë‹¤ìˆ˜: {len(emojis)}ê°œ")
        
        # 2. ì™¸êµ­ì–´ ì„ì„
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', full_text))
        japanese_chars = len(re.findall(r'[\u3040-\u30ff]', full_text))
        thai_chars = len(re.findall(r'[\u0e00-\u0e7f]', full_text))
        russian_chars = len(re.findall(r'[\u0400-\u04ff]', full_text))
        
        foreign_chars = chinese_chars + japanese_chars + thai_chars + russian_chars
        if foreign_chars > 0:
            hallucination_score += 40
            reasons.append(f"ì™¸êµ­ì–´ ì„ì„: {foreign_chars}ì")
        
        # 3. í•œì˜ í˜¼í•© ë‹¨ì–´
        korean_english_mixed = re.findall(r'[ê°€-í£]+[a-zA-Z]+|[a-zA-Z]+[ê°€-í£]+', full_text)
        if korean_english_mixed:
            hallucination_score += 35
            reasons.append(f"í•œì˜ í˜¼í•©: {korean_english_mixed[:3]}")
        
        # 4. í™˜ê° íŒ¨í„´
        found_patterns = [p for p in self.hallucination_patterns if p.lower() in full_text.lower()]
        if found_patterns:
            hallucination_score += 25
            reasons.append(f"í™˜ê° íŒ¨í„´: {found_patterns[:3]}")
        
        # 5. ë‹¨ì–´ ë°˜ë³µ
        words = full_text.split()
        if len(words) >= 5:
            word_counts = {}
            for w in words:
                clean = self.emoji_pattern.sub('', w).strip()
                if clean:
                    word_counts[clean] = word_counts.get(clean, 0) + 1
            
            if word_counts:
                max_word = max(word_counts, key=word_counts.get)
                max_repeat = word_counts[max_word]
                
                if max_repeat >= 5 and max_repeat / len(words) >= 0.15:
                    hallucination_score += 40
                    reasons.append(f"ë‹¨ì–´ ë°˜ë³µ: '{max_word}' {max_repeat}íšŒ")
                
                if max_repeat >= 10:
                    hallucination_score += 30
                    reasons.append(f"ì‹¬ê°í•œ ë°˜ë³µ: {max_repeat}íšŒ")
        
        # 6. ì„¸ê·¸ë¨¼íŠ¸ ë°˜ë³µ
        if len(segments) >= 5:
            seg_texts = [s.get('text', '').strip() for s in segments]
            seg_counts = {}
            for t in seg_texts:
                if t:
                    seg_counts[t] = seg_counts.get(t, 0) + 1
            
            if seg_counts:
                max_seg = max(seg_counts, key=seg_counts.get)
                max_seg_repeat = seg_counts[max_seg]
                
                if max_seg_repeat >= 5:
                    hallucination_score += 50
                    reasons.append(f"ì„¸ê·¸ë¨¼íŠ¸ ë°˜ë³µ: '{max_seg}' {max_seg_repeat}íšŒ")
        
        # 7. ë‹¨ì¼ ë¬¸ì/ìˆ«ì ë‚˜ì—´
        single_chars = re.findall(r'\b[0-9]\b|\b[ã„±-ã…ã…-ã…£]\b|\b[a-zA-Z]\b', full_text)
        if len(single_chars) >= 10:
            hallucination_score += 35
            reasons.append(f"ë‹¨ì¼ ë¬¸ì ë‚˜ì—´: {len(single_chars)}ê°œ")
        
        # 8. ë§¥ë½ ì—†ëŠ” ì˜ì–´
        english_words = re.findall(r'\b[a-zA-Z]{3,}\b', full_text)
        if english_words:
            cooking_english = ['sauce', 'chicken', 'cheese', 'cream', 'butter', 'oil', 'salt', 'sugar']
            non_cooking = [w for w in english_words if w.lower() not in cooking_english]
            
            if len(non_cooking) >= 3:
                hallucination_score += 30
                reasons.append(f"ë§¥ë½ ì—†ëŠ” ì˜ì–´: {non_cooking[:5]}")
        
        is_hallucination = hallucination_score >= 40
        
        if reasons:
            print(f"    ğŸ” í™˜ê° ê²€ì‚¬: ì ìˆ˜={hallucination_score}, ì´ìœ ={reasons}")
        
        return is_hallucination, ", ".join(reasons)
    
    def _get_duration(self, file_path: str) -> float:
        """ffprobeë¡œ ì˜ìƒ ê¸¸ì´ ì¶”ì¶œ"""
        try:
            cmd = [
                'ffprobe', '-v', 'quiet',
                '-print_format', 'json',
                '-show_format', file_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                data = json.loads(result.stdout)
                duration = float(data.get('format', {}).get('duration', 0))
                return round(duration, 2)
            return None
        except:
            return None
    
    def _extract_audio(self, video_path: str) -> str:
        """ffmpegë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
        temp_dir = tempfile.gettempdir()
        audio_path = os.path.join(temp_dir, 'naos_audio_temp.mp3')
        
        try:
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vn', '-acodec', 'libmp3lame',
                '-ab', '128k', '-ar', '44100', '-ac', '2',
                '-y', audio_path
            ]
            result = subprocess.run(cmd, capture_output=True, timeout=120)
            
            if result.returncode == 0 and os.path.exists(audio_path):
                return audio_path
            return None
        except:
            return None
    
    def _transcribe(self, file_path: str) -> dict:
        """Whisper API í˜¸ì¶œ"""
        file_size = os.path.getsize(file_path)
        if file_size > 25 * 1024 * 1024:
            print(f"    âš ï¸ íŒŒì¼ì´ 25MB ì´ˆê³¼, ì••ì¶• ì¤‘...")
            compressed = self._compress_audio(file_path)
            if compressed:
                file_path = compressed
        
        with open(file_path, 'rb') as f:
            response = self.client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                language="ko",
                timestamp_granularities=["segment"]
            )
        
        segments = []
        if hasattr(response, 'segments') and response.segments:
            for idx, seg in enumerate(response.segments):
                segments.append({
                    "index": idx,
                    "start": round(seg.start, 2),
                    "end": round(seg.end, 2),
                    "text": seg.text.strip()
                })
        
        detected_duration = segments[-1].get('end') if segments else None
        
        return {
            "segments": segments,
            "full_text": response.text.strip() if hasattr(response, 'text') else "",
            "detected_duration": detected_duration
        }
    
    def _compress_audio(self, audio_path: str) -> str:
        """ì˜¤ë””ì˜¤ ì••ì¶•"""
        temp_dir = tempfile.gettempdir()
        compressed = os.path.join(temp_dir, 'naos_compressed_temp.mp3')
        
        try:
            cmd = [
                'ffmpeg', '-i', audio_path,
                '-acodec', 'libmp3lame',
                '-ab', '64k', '-ar', '16000', '-ac', '1',
                '-y', compressed
            ]
            result = subprocess.run(cmd, capture_output=True, timeout=60)
            
            if result.returncode == 0 and os.path.exists(compressed):
                return compressed
            return None
        except:
            return None
    
    def _get_suffix(self, filename: str) -> str:
        if filename and '.' in filename:
            return '.' + filename.rsplit('.', 1)[1].lower()
        return '.mp4'
    
    def _get_suffix_from_url(self, url: str) -> str:
        path = url.split('?')[0]
        if '.' in path:
            return '.' + path.rsplit('.', 1)[1].lower()
        return '.mp4'
